{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "domrnonINuu4"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTAVwaaOFuEf"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/academics/programs/index.html)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 8 Assignment: Feature Engineering**\n",
    "\n",
    "**Student Name: Your Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YUdI4CcFuEg"
   },
   "source": [
    "# Assignment Instructions\n",
    "\n",
    "This assignment is similar to assignment 5, except that you must use feature engineering to solve it.  I provide you with a dataset that contains dimensions and the quality of items of specific shapes.  With the values of 'height', 'width', 'depth'. 'shape', and 'quality' you should try to predict the cost of these items.  You should be able to match very close to solution file, if you feature engineer correctly.  To get full credit your average cost should not be more than 50 off from the solution.  The autocorrector will let you know if you are in this range.\n",
    "\n",
    "You can find all of the needed CSV files here:\n",
    "\n",
    "* [Shapes - Training](https://data.heatonresearch.com/data/t81-558/datasets/shapes-train.csv)\n",
    "* [Shapes - Submit](https://data.heatonresearch.com/data/t81-558/datasets/shapes-test.csv)\n",
    "\n",
    "Use the training file to train your neural network and submit results for for the data contained in the test/submit file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9ZvFFOR5A-Wo",
    "outputId": "79139a73-499a-47fd-e623-cfbd26c8f9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qrsT_KZFuEh"
   },
   "source": [
    "# Assignment Submit Function\n",
    "\n",
    "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
    "\n",
    "**It is unlikely that should need to modify this function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43KOAL0OFuEi"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if type(item) is PIL.Image.Image:\n",
    "            buffered = BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif type(item) is pd.core.frame.DataFrame:\n",
    "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code==200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "zd5fX98YFuEm"
   },
   "source": [
    "# Assignment #8 Sample Code\n",
    "\n",
    "The following code provides a starting point for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=50, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "def perturbation_rank(device, model, x, y, names, regression):\n",
    "    model.to(device)\n",
    "    model.eval() # set the model to evaluation mode\n",
    "\n",
    "    #x = torch.tensor(x).float().to(device)\n",
    "    #y = torch.tensor(y).float().to(device)\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        hold = x[:, i].clone()\n",
    "        x[:, i] = torch.randperm(x.shape[0]).to(device)  # shuffling\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "\n",
    "        if regression:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            error = loss_fn(y, pred).item()\n",
    "        else:\n",
    "            # pred should be probabilities; apply softmax if not done in model's forward method\n",
    "            if len(pred.shape) == 2 and pred.shape[1] > 1:\n",
    "                pred = F.softmax(pred, dim=1)\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "                error = loss_fn(pred, y.long()).item()\n",
    "            else:\n",
    "                loss_fn = nn.MSELoss()\n",
    "                error = loss_fn(y, pred).item()\n",
    "            \n",
    "            \n",
    "        errors.append(error)\n",
    "        x[:, i] = hold\n",
    "        \n",
    "    max_error = max(errors)\n",
    "    importance = [e/max_error for e in errors]\n",
    "\n",
    "    data = {'name':names, 'error':errors, 'importance':importance}\n",
    "    result = pd.DataFrame(data, columns=['name', 'error', 'importance'])\n",
    "    result.sort_values(by=['importance'], ascending=[0], inplace=True)\n",
    "    result.reset_index(inplace=True, drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['height', 'width', 'depth', 'quality', 'box', 'cylinder', 'ellipsoid'], dtype='object')\n",
      "0        200.49\n",
      "1       1175.71\n",
      "2        131.72\n",
      "3         15.83\n",
      "4        340.21\n",
      "         ...   \n",
      "9995    3918.36\n",
      "9996      35.57\n",
      "9997     325.90\n",
      "9998     481.23\n",
      "9999     824.83\n",
      "Name: cost, Length: 10000, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, tloss: 8715.2001953125, vloss: 116250.695312, EStop:[]: 100%|██████████| 469/469 [00:04<00:00, 108.89it/s]\n",
      "Epoch: 2, tloss: 103877.78125, vloss: 62129.804688, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:03<00:00, 119.22it/s]\n",
      "Epoch: 3, tloss: 8979.873046875, vloss: 55541.324219, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 116.07it/s]\n",
      "Epoch: 4, tloss: 149801.6875, vloss: 58336.093750, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:03<00:00, 118.43it/s]\n",
      "Epoch: 5, tloss: 34558.9609375, vloss: 50142.160156, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:03<00:00, 117.68it/s]\n",
      "Epoch: 6, tloss: 89361.4921875, vloss: 39417.894531, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:03<00:00, 117.91it/s]\n",
      "Epoch: 7, tloss: 157668.65625, vloss: 39259.000000, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:03<00:00, 118.39it/s]\n",
      "Epoch: 8, tloss: 15997.51953125, vloss: 46595.050781, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:03<00:00, 117.76it/s]\n",
      "Epoch: 9, tloss: 92531.6171875, vloss: 77852.117188, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.42it/s]\n",
      "Epoch: 10, tloss: 15881.337890625, vloss: 27548.316406, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 116.51it/s]\n",
      "Epoch: 11, tloss: 56144.640625, vloss: 41863.378906, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 115.53it/s]\n",
      "Epoch: 12, tloss: 16066.796875, vloss: 51458.089844, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.01it/s]\n",
      "Epoch: 13, tloss: 52328.34375, vloss: 22856.300781, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 116.50it/s]\n",
      "Epoch: 14, tloss: 4631.0478515625, vloss: 29730.076172, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 113.73it/s]\n",
      "Epoch: 15, tloss: 24277.04296875, vloss: 18356.652344, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 115.89it/s]\n",
      "Epoch: 16, tloss: 9310.638671875, vloss: 43852.742188, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.58it/s]\n",
      "Epoch: 17, tloss: 3695.2529296875, vloss: 21620.126953, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.58it/s]\n",
      "Epoch: 18, tloss: 31870.05859375, vloss: 16427.189453, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 114.53it/s]\n",
      "Epoch: 19, tloss: 48156.6171875, vloss: 32213.039062, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.58it/s]\n",
      "Epoch: 20, tloss: 5880.1904296875, vloss: 19732.357422, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 115.76it/s]\n",
      "Epoch: 21, tloss: 61399.52734375, vloss: 20502.949219, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.39it/s]\n",
      "Epoch: 22, tloss: 6647.0009765625, vloss: 18187.890625, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.12it/s]\n",
      "Epoch: 23, tloss: 17466.15234375, vloss: 14961.548828, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 113.68it/s]\n",
      "Epoch: 24, tloss: 32014.685546875, vloss: 13801.170898, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 111.31it/s]\n",
      "Epoch: 25, tloss: 23099.625, vloss: 10303.496094, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 111.34it/s]\n",
      "Epoch: 26, tloss: 17639.27734375, vloss: 11874.768555, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 115.25it/s]\n",
      "Epoch: 27, tloss: 8466.462890625, vloss: 10657.452148, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.97it/s]\n",
      "Epoch: 28, tloss: 1516.8382568359375, vloss: 13312.333984, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.93it/s]\n",
      "Epoch: 29, tloss: 5133.50537109375, vloss: 11372.739258, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.36it/s]\n",
      "Epoch: 30, tloss: 8772.140625, vloss: 11529.600586, EStop:[No improvement in the last 5 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.47it/s]\n",
      "Epoch: 31, tloss: 3068.088623046875, vloss: 29614.646484, EStop:[No improvement in the last 6 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.09it/s]\n",
      "Epoch: 32, tloss: 24565.1796875, vloss: 43594.507812, EStop:[No improvement in the last 7 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.72it/s]\n",
      "Epoch: 33, tloss: 24924.810546875, vloss: 12565.980469, EStop:[No improvement in the last 8 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.65it/s]\n",
      "Epoch: 34, tloss: 20468.84375, vloss: 11270.078125, EStop:[No improvement in the last 9 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.63it/s]\n",
      "Epoch: 35, tloss: 49716.71875, vloss: 19425.074219, EStop:[No improvement in the last 10 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.17it/s]\n",
      "Epoch: 36, tloss: 28372.693359375, vloss: 12544.902344, EStop:[No improvement in the last 11 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.46it/s]\n",
      "Epoch: 37, tloss: 8960.96875, vloss: 22530.250000, EStop:[No improvement in the last 12 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.80it/s]\n",
      "Epoch: 38, tloss: 930.703857421875, vloss: 11693.828125, EStop:[No improvement in the last 13 epochs]: 100%|██████████| 469/469 [00:04<00:00, 113.92it/s]\n",
      "Epoch: 39, tloss: 1727.2259521484375, vloss: 8300.895508, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 112.40it/s]\n",
      "Epoch: 40, tloss: 18822.8515625, vloss: 11434.897461, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.57it/s]\n",
      "Epoch: 41, tloss: 48495.12109375, vloss: 7036.644531, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 112.72it/s]\n",
      "Epoch: 42, tloss: 2622.57958984375, vloss: 16631.419922, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.63it/s]\n",
      "Epoch: 43, tloss: 4288.603515625, vloss: 8203.132812, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.10it/s]\n",
      "Epoch: 44, tloss: 3019.18115234375, vloss: 6863.460449, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 113.16it/s]\n",
      "Epoch: 45, tloss: 19594.419921875, vloss: 16688.152344, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 114.24it/s]\n",
      "Epoch: 46, tloss: 3170.64208984375, vloss: 17675.513672, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.71it/s]\n",
      "Epoch: 47, tloss: 4369.5546875, vloss: 18888.740234, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 113.60it/s]\n",
      "Epoch: 48, tloss: 4268.9150390625, vloss: 9380.534180, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.08it/s]\n",
      "Epoch: 49, tloss: 1291.23974609375, vloss: 33224.812500, EStop:[No improvement in the last 5 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.31it/s]\n",
      "Epoch: 50, tloss: 3062.3505859375, vloss: 9358.929688, EStop:[No improvement in the last 6 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.93it/s]\n",
      "Epoch: 51, tloss: 7676.43115234375, vloss: 7769.626953, EStop:[No improvement in the last 7 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.83it/s]\n",
      "Epoch: 52, tloss: 1246.63623046875, vloss: 8310.709961, EStop:[No improvement in the last 8 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.85it/s]\n",
      "Epoch: 53, tloss: 1628.096435546875, vloss: 4951.122559, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 112.28it/s]\n",
      "Epoch: 54, tloss: 1790.6484375, vloss: 7888.584473, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 113.55it/s]\n",
      "Epoch: 55, tloss: 2294.207763671875, vloss: 5428.580078, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 108.79it/s]\n",
      "Epoch: 56, tloss: 8562.12109375, vloss: 5492.706543, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:03<00:00, 125.36it/s]\n",
      "Epoch: 57, tloss: 1198.547119140625, vloss: 10877.458984, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:03<00:00, 120.40it/s]\n",
      "Epoch: 58, tloss: 2070.225830078125, vloss: 5974.388672, EStop:[No improvement in the last 5 epochs]: 100%|██████████| 469/469 [00:03<00:00, 127.05it/s]\n",
      "Epoch: 59, tloss: 1580.7412109375, vloss: 8407.766602, EStop:[No improvement in the last 6 epochs]: 100%|██████████| 469/469 [00:03<00:00, 127.91it/s]\n",
      "Epoch: 60, tloss: 919.279296875, vloss: 4287.510254, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:03<00:00, 124.90it/s]\n",
      "Epoch: 61, tloss: 6087.0185546875, vloss: 8560.910156, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:03<00:00, 125.01it/s]\n",
      "Epoch: 62, tloss: 10413.3076171875, vloss: 10446.360352, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.57it/s]\n",
      "Epoch: 63, tloss: 10949.7490234375, vloss: 9286.168945, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 106.04it/s]\n",
      "Epoch: 64, tloss: 5079.513671875, vloss: 9652.320312, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.76it/s]\n",
      "Epoch: 65, tloss: 1450.0306396484375, vloss: 4708.554688, EStop:[No improvement in the last 5 epochs]: 100%|██████████| 469/469 [00:03<00:00, 118.95it/s]\n",
      "Epoch: 66, tloss: 3844.621826171875, vloss: 5142.522949, EStop:[No improvement in the last 6 epochs]: 100%|██████████| 469/469 [00:03<00:00, 121.74it/s]\n",
      "Epoch: 67, tloss: 7452.0556640625, vloss: 8558.796875, EStop:[No improvement in the last 7 epochs]: 100%|██████████| 469/469 [00:03<00:00, 123.76it/s]\n",
      "Epoch: 68, tloss: 5786.21240234375, vloss: 4786.343750, EStop:[No improvement in the last 8 epochs]: 100%|██████████| 469/469 [00:03<00:00, 124.96it/s]\n",
      "Epoch: 69, tloss: 10811.181640625, vloss: 3316.291992, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:03<00:00, 121.06it/s]\n",
      "Epoch: 70, tloss: 9577.7998046875, vloss: 11177.518555, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.32it/s]\n",
      "Epoch: 71, tloss: 1378.914306640625, vloss: 5559.254883, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.23it/s]\n",
      "Epoch: 72, tloss: 1177.572265625, vloss: 4583.063965, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.34it/s]\n",
      "Epoch: 73, tloss: 7775.76708984375, vloss: 4279.540039, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.14it/s]\n",
      "Epoch: 74, tloss: 1581.6341552734375, vloss: 3200.350586, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 102.71it/s]\n",
      "Epoch: 75, tloss: 1941.1097412109375, vloss: 4309.182129, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.59it/s]\n",
      "Epoch: 76, tloss: 3145.7890625, vloss: 2898.735107, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 110.00it/s]\n",
      "Epoch: 77, tloss: 3862.34765625, vloss: 3560.170410, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 108.95it/s]\n",
      "Epoch: 78, tloss: 2384.135986328125, vloss: 4282.829590, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 106.51it/s]\n",
      "Epoch: 79, tloss: 2076.572021484375, vloss: 6349.309082, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 107.09it/s]\n",
      "Epoch: 80, tloss: 11859.5341796875, vloss: 12112.577148, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.24it/s]\n",
      "Epoch: 81, tloss: 1209.025146484375, vloss: 7300.337402, EStop:[No improvement in the last 5 epochs]: 100%|██████████| 469/469 [00:04<00:00, 104.66it/s]\n",
      "Epoch: 82, tloss: 12151.1865234375, vloss: 6455.316406, EStop:[No improvement in the last 6 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.89it/s]\n",
      "Epoch: 83, tloss: 5792.5869140625, vloss: 5323.312012, EStop:[No improvement in the last 7 epochs]: 100%|██████████| 469/469 [00:04<00:00, 108.14it/s]\n",
      "Epoch: 84, tloss: 1050.732421875, vloss: 3932.489502, EStop:[No improvement in the last 8 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.25it/s]\n",
      "Epoch: 85, tloss: 3807.23193359375, vloss: 22273.740234, EStop:[No improvement in the last 9 epochs]: 100%|██████████| 469/469 [00:04<00:00, 108.53it/s]\n",
      "Epoch: 86, tloss: 4673.84716796875, vloss: 6045.458008, EStop:[No improvement in the last 10 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.28it/s]\n",
      "Epoch: 87, tloss: 7614.55615234375, vloss: 8200.910156, EStop:[No improvement in the last 11 epochs]: 100%|██████████| 469/469 [00:04<00:00, 113.14it/s]\n",
      "Epoch: 88, tloss: 941.912109375, vloss: 5240.615723, EStop:[No improvement in the last 12 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.12it/s]\n",
      "Epoch: 89, tloss: 15817.4365234375, vloss: 4445.396484, EStop:[No improvement in the last 13 epochs]: 100%|██████████| 469/469 [00:04<00:00, 105.39it/s]\n",
      "Epoch: 90, tloss: 872.282958984375, vloss: 6675.833008, EStop:[No improvement in the last 14 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.24it/s]\n",
      "Epoch: 91, tloss: 9560.7197265625, vloss: 25756.404297, EStop:[No improvement in the last 15 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.14it/s]\n",
      "Epoch: 92, tloss: 1850.191650390625, vloss: 4925.779297, EStop:[No improvement in the last 16 epochs]: 100%|██████████| 469/469 [00:04<00:00, 106.60it/s]\n",
      "Epoch: 93, tloss: 766.1207885742188, vloss: 2746.437012, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 110.44it/s]\n",
      "Epoch: 94, tloss: 1787.876953125, vloss: 4419.878906, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 111.26it/s]\n",
      "Epoch: 95, tloss: 1177.6282958984375, vloss: 4253.359863, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.02it/s]\n",
      "Epoch: 96, tloss: 1038.4501953125, vloss: 2444.341797, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 109.12it/s]\n",
      "Epoch: 97, tloss: 6262.685546875, vloss: 3929.208008, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.58it/s]\n",
      "Epoch: 98, tloss: 3588.89892578125, vloss: 3503.220703, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 112.66it/s]\n",
      "Epoch: 99, tloss: 3372.068359375, vloss: 8122.428711, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.25it/s]\n",
      "Epoch: 100, tloss: 1328.909423828125, vloss: 15661.956055, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.06it/s]\n",
      "Epoch: 101, tloss: 1234.2633056640625, vloss: 3197.392334, EStop:[No improvement in the last 5 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.45it/s]\n",
      "Epoch: 102, tloss: 1410.87841796875, vloss: 3996.571045, EStop:[No improvement in the last 6 epochs]: 100%|██████████| 469/469 [00:04<00:00, 108.27it/s]\n",
      "Epoch: 103, tloss: 14473.845703125, vloss: 6707.579102, EStop:[No improvement in the last 7 epochs]: 100%|██████████| 469/469 [00:04<00:00, 108.07it/s]\n",
      "Epoch: 104, tloss: 15623.431640625, vloss: 7697.948730, EStop:[No improvement in the last 8 epochs]: 100%|██████████| 469/469 [00:04<00:00, 108.35it/s]\n",
      "Epoch: 105, tloss: 20886.603515625, vloss: 6966.352051, EStop:[No improvement in the last 9 epochs]: 100%|██████████| 469/469 [00:04<00:00, 106.51it/s]\n",
      "Epoch: 106, tloss: 5620.87255859375, vloss: 2770.056152, EStop:[No improvement in the last 10 epochs]: 100%|██████████| 469/469 [00:04<00:00, 107.78it/s]\n",
      "Epoch: 107, tloss: 2477.082763671875, vloss: 5150.380371, EStop:[No improvement in the last 11 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.21it/s]\n",
      "Epoch: 108, tloss: 1828.873291015625, vloss: 4126.430664, EStop:[No improvement in the last 12 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.98it/s]\n",
      "Epoch: 109, tloss: 11872.0810546875, vloss: 6838.126465, EStop:[No improvement in the last 13 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.54it/s]\n",
      "Epoch: 110, tloss: 846.7950439453125, vloss: 2610.378662, EStop:[No improvement in the last 14 epochs]: 100%|██████████| 469/469 [00:04<00:00, 107.60it/s]\n",
      "Epoch: 111, tloss: 3564.621826171875, vloss: 3180.085938, EStop:[No improvement in the last 15 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.87it/s]\n",
      "Epoch: 112, tloss: 4940.6005859375, vloss: 2210.127686, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 111.74it/s]\n",
      "Epoch: 113, tloss: 5185.09326171875, vloss: 2232.846680, EStop:[No improvement in the last 1 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.19it/s]\n",
      "Epoch: 114, tloss: 647.1525268554688, vloss: 3290.847412, EStop:[No improvement in the last 2 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.48it/s]\n",
      "Epoch: 115, tloss: 7527.5341796875, vloss: 9966.636719, EStop:[No improvement in the last 3 epochs]: 100%|██████████| 469/469 [00:04<00:00, 110.72it/s]\n",
      "Epoch: 116, tloss: 1696.496826171875, vloss: 2487.438232, EStop:[No improvement in the last 4 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.95it/s]\n",
      "Epoch: 117, tloss: 10795.98828125, vloss: 2215.832764, EStop:[No improvement in the last 5 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.22it/s]\n",
      "Epoch: 118, tloss: 28222.71875, vloss: 6471.666016, EStop:[No improvement in the last 6 epochs]: 100%|██████████| 469/469 [00:04<00:00, 109.61it/s]\n",
      "Epoch: 119, tloss: 1131.97607421875, vloss: 1905.213135, EStop:[Improvement found, counter reset to 0]: 100%|██████████| 469/469 [00:04<00:00, 106.37it/s]\n",
      "Epoch: 120, tloss 2011.7369384765625:  89%|████████▊ | 416/469 [00:03<00:00, 110.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zixuanni/Desktop/T81-558/assignment_zixuan_class8.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zixuanni/Desktop/T81-558/assignment_zixuan_class8.ipynb#X12sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zixuanni/Desktop/T81-558/assignment_zixuan_class8.ipynb#X12sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (x_batch, y_batch) \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zixuanni/Desktop/T81-558/assignment_zixuan_class8.ipynb#X12sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     y_batch_pred \u001b[39m=\u001b[39m model(x_batch)\u001b[39m.\u001b[39mflatten()  \u001b[39m#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zixuanni/Desktop/T81-558/assignment_zixuan_class8.ipynb#X12sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(y_batch_pred, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zixuanni/Desktop/T81-558/assignment_zixuan_class8.ipynb#X12sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:82\u001b[0m, in \u001b[0;36mOptimizedModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdynamo_ctx(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orig_mod\u001b[39m.\u001b[39;49mforward)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    210\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    211\u001b[0m \u001b[39m# NB: We can't really type check this function as the type of input\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m# may change dynamically (as is tested in\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m# TestScript.test_sequential_intermediary_types).  Cannot annotate\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39m# with Any as TorchScript expects a more precise type\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m    217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    210\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:2836\u001b[0m, in \u001b[0;36maot_module_simplified.<locals>.forward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   2834\u001b[0m full_args\u001b[39m.\u001b[39mextend(params_flat)\n\u001b[1;32m   2835\u001b[0m full_args\u001b[39m.\u001b[39mextend(runtime_args)\n\u001b[0;32m-> 2836\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn(full_args)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1224\u001b[0m, in \u001b[0;36mmake_boxed_func.<locals>.g\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg\u001b[39m(args):\n\u001b[0;32m-> 1224\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:2403\u001b[0m, in \u001b[0;36maot_dispatch_autograd.<locals>.debug_compiled_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m can_require_grad:\n\u001b[1;32m   2398\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m a\u001b[39m.\u001b[39mrequires_grad, format_guard_bug_msg(\n\u001b[1;32m   2399\u001b[0m             aot_config,\n\u001b[1;32m   2400\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdescribe_input(i,\u001b[39m \u001b[39maot_config)\u001b[39m}\u001b[39;00m\u001b[39m would not require grad\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2401\u001b[0m         )\n\u001b[0;32m-> 2403\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_function(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1900\u001b[0m, in \u001b[0;36mcreate_runtime_wrapper.<locals>.runtime_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     args_with_synthetic_bases \u001b[39m=\u001b[39m args\n\u001b[1;32m   1899\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39m_force_original_view_tracking(\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m-> 1900\u001b[0m     all_outs \u001b[39m=\u001b[39m call_func_with_args(\n\u001b[1;32m   1901\u001b[0m         compiled_fn,\n\u001b[1;32m   1902\u001b[0m         args_with_synthetic_bases,\n\u001b[1;32m   1903\u001b[0m         disable_amp\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1904\u001b[0m     )\n\u001b[1;32m   1906\u001b[0m num_mutated_inps \u001b[39m=\u001b[39m runtime_metadata\u001b[39m.\u001b[39mnum_mutated_inputs\n\u001b[1;32m   1907\u001b[0m num_metadata_mutated_inps \u001b[39m=\u001b[39m runtime_metadata\u001b[39m.\u001b[39mnum_mutated_metadata_inputs\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1249\u001b[0m, in \u001b[0;36mcall_func_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m\"\u001b[39m\u001b[39m_boxed_call\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1249\u001b[0m         out \u001b[39m=\u001b[39m normalize_as_list(f(args))\n\u001b[1;32m   1250\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m         \u001b[39m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m         \u001b[39m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYour compiler for AOTAutograd is returning a a function that doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt take boxed arguments. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1256\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1257\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1224\u001b[0m, in \u001b[0;36mmake_boxed_func.<locals>.g\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg\u001b[39m(args):\n\u001b[0;32m-> 1224\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:2168\u001b[0m, in \u001b[0;36maot_dispatch_autograd.<locals>.CompiledFunction.forward\u001b[0;34m(ctx, *deduped_flat_tensor_args)\u001b[0m\n\u001b[1;32m   2160\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m   2161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, \u001b[39m*\u001b[39mdeduped_flat_tensor_args):\n\u001b[1;32m   2162\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2166\u001b[0m     \u001b[39m# - Note that in the synthetic bases case, mutated_inputs will correspond to an updated version\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m     \u001b[39m#   of the original view, and not the synthetic base\u001b[39;00m\n\u001b[0;32m-> 2168\u001b[0m     fw_outs \u001b[39m=\u001b[39m call_func_with_args(\n\u001b[1;32m   2169\u001b[0m         CompiledFunction\u001b[39m.\u001b[39;49mcompiled_fw,\n\u001b[1;32m   2170\u001b[0m         deduped_flat_tensor_args,\n\u001b[1;32m   2171\u001b[0m         disable_amp\u001b[39m=\u001b[39;49mdisable_amp,\n\u001b[1;32m   2172\u001b[0m     )\n\u001b[1;32m   2174\u001b[0m     num_outputs \u001b[39m=\u001b[39m CompiledFunction\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mnum_outputs\n\u001b[1;32m   2175\u001b[0m     num_outputs_aliased_to_inputs \u001b[39m=\u001b[39m (\n\u001b[1;32m   2176\u001b[0m         CompiledFunction\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mnum_outputs_aliased_to_inputs\n\u001b[1;32m   2177\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1249\u001b[0m, in \u001b[0;36mcall_func_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m\"\u001b[39m\u001b[39m_boxed_call\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1249\u001b[0m         out \u001b[39m=\u001b[39m normalize_as_list(f(args))\n\u001b[1;32m   1250\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m         \u001b[39m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m         \u001b[39m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYour compiler for AOTAutograd is returning a a function that doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt take boxed arguments. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1256\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1257\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1224\u001b[0m, in \u001b[0;36mmake_boxed_func.<locals>.g\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg\u001b[39m(args):\n\u001b[0;32m-> 1224\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/fx/graph_module.py:662\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_wrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 662\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_call(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/fx/graph_module.py:271\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_call(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    270\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcls, obj)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[39massert\u001b[39;00m e\u001b[39m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.76:5\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7):\n\u001b[0;32m----> 5\u001b[0m     t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49maten\u001b[39m.\u001b[39;49mt\u001b[39m.\u001b[39;49mdefault(primals_1)\n\u001b[1;32m      6\u001b[0m     addmm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39maten\u001b[39m.\u001b[39maddmm\u001b[39m.\u001b[39mdefault(primals_2, primals_7, t);  primals_2 \u001b[39m=\u001b[39m t \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     relu \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39maten\u001b[39m.\u001b[39mrelu\u001b[39m.\u001b[39mdefault(addmm);  addmm \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/_ops.py:287\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = 'mps'\n",
    "# Read the MPG dataset.\n",
    "df =pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/shapes-train.csv\")\n",
    "\n",
    "# Pandas to Numpy\n",
    "df_dummies = pd.get_dummies(df['shape']).astype(int)\n",
    "df = pd.concat([df, df_dummies], axis=1)\n",
    "result = df['cost']\n",
    "x_columns = df.columns.drop(['shape', 'cost', 'id'])\n",
    "x = df[x_columns].values\n",
    "print(x_columns)\n",
    "print(result)\n",
    "y = result.values  # regression\n",
    "\n",
    "# Split into validation and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Numpy to Torch Tensor\n",
    "x_train = torch.tensor(x_train, device=device, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, device=device, dtype=torch.float32)\n",
    "\n",
    "x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, device=device, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "dataset_train = TensorDataset(x_train, y_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "dataset_test = TensorDataset(x_test, y_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# Create model\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x_train.shape[1], 50), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(50, 25), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(25, 1)\n",
    ")\n",
    "\n",
    "model = torch.compile(model, backend=\"aot_eager\").to(device)\n",
    "\n",
    "# Define the loss function for regression\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "es = EarlyStopping()\n",
    "\n",
    "epoch = 0\n",
    "done = False\n",
    "while epoch < 1000 and not done:\n",
    "    epoch += 1\n",
    "    steps = list(enumerate(dataloader_train))\n",
    "    pbar = tqdm.tqdm(steps)\n",
    "    model.train()\n",
    "    for i, (x_batch, y_batch) in pbar:\n",
    "        y_batch_pred = model(x_batch).flatten()  #\n",
    "        loss = loss_fn(y_batch_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss, current = loss.item(), (i + 1) * len(x_batch)\n",
    "        if i == len(steps) - 1:\n",
    "            model.eval()\n",
    "            pred = model(x_test).flatten()\n",
    "            vloss = loss_fn(pred, y_test)\n",
    "            if es(model, vloss):\n",
    "                done = True\n",
    "            pbar.set_description(\n",
    "                f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:>7f}, EStop:[{es.status}]\"\n",
    "            )\n",
    "        else:\n",
    "            pbar.set_description(f\"Epoch: {epoch}, tloss {loss:}\")\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "pred = model(x_test)\n",
    "score = torch.sqrt(torch.nn.functional.mse_loss(pred.flatten(), y_test))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['height', 'width', 'depth', 'quality', 'box', 'cylinder', 'ellipsoid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2500, 1])) that is different to the input size (torch.Size([2500])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>box</td>\n",
       "      <td>8.109905e+08</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cylinder</td>\n",
       "      <td>4.538349e+08</td>\n",
       "      <td>0.559606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>width</td>\n",
       "      <td>4.328165e+07</td>\n",
       "      <td>0.053369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>height</td>\n",
       "      <td>3.854457e+07</td>\n",
       "      <td>0.047528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depth</td>\n",
       "      <td>2.261670e+07</td>\n",
       "      <td>0.027888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ellipsoid</td>\n",
       "      <td>2.005783e+07</td>\n",
       "      <td>0.024733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quality</td>\n",
       "      <td>9.759306e+05</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name         error  importance\n",
       "0        box  8.109905e+08    1.000000\n",
       "1   cylinder  4.538349e+08    0.559606\n",
       "2      width  4.328165e+07    0.053369\n",
       "3     height  3.854457e+07    0.047528\n",
       "4      depth  2.261670e+07    0.027888\n",
       "5  ellipsoid  2.005783e+07    0.024733\n",
       "6    quality  9.759306e+05    0.001203"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "names = list(df.columns) # x+y column name\n",
    "names.remove('id')\n",
    "names.remove('shape')\n",
    "names.remove(\"cost\") # remove the target(y)\n",
    "print(names)\n",
    "rank = perturbation_rank(device, model, x_test, y_test, names, True)\n",
    "display(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            cost     id\n",
      "0      10.905555  10001\n",
      "1     336.237671  10002\n",
      "2      20.813232  10003\n",
      "3     981.914978  10004\n",
      "4     266.961121  10005\n",
      "...          ...    ...\n",
      "1995  824.682800  11996\n",
      "1996  278.743805  11997\n",
      "1997  241.665329  11998\n",
      "1998   39.184223  11999\n",
      "1999   11.798323  12000\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "Success: Submitted Assignment 8 for n.zixuan:\n",
      "You have submitted this assignment 8 times. (this is fine)\n",
      "Note: The mean difference 18.44340547050001 for column 'cost' is acceptable and is less than the maximum allowed value of '50.0' for this assignment.\n",
      "No warnings or errors (only notes), you will probably do well, but no guarantee. :-)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# This is your student key that I emailed to you at the beginnning of the semester.\n",
    "key = \"r2nrqz2pX53SGKnwA07UW52mBbNzuLpf8e2ZYIV9\"  # This is an example key and will not work.\n",
    "\n",
    "# You must also identify your source file.  (modify for your local setup)\n",
    "file='/Users/zixuanni/Desktop/T81-558/assignment_zixuan_class8.ipynb'  # Google CoLab\n",
    "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class8.ipynb'  # Windows\n",
    "# file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class8.ipynb'  # Mac/Linux\n",
    "\n",
    "# Begin assignment\n",
    "df_train = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/shapes-train.csv\")\n",
    "df_submit = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/shapes-test.csv\")\n",
    "id = df_submit['id']\n",
    "df_dummies = pd.get_dummies(df_submit['shape']).astype(int)\n",
    "df_submit = pd.concat([df_submit, df_dummies], axis=1)\n",
    "x_columns = df_submit.columns.drop(['shape', 'id'])\n",
    "x = df_submit[x_columns].values\n",
    "x_pred = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "pred = model(x_pred)\n",
    "df_submit = pd.DataFrame(pred.cpu().detach().numpy())\n",
    "df_submit.rename(columns={df_submit.columns[0]: 'cost'}, inplace=True)\n",
    "df_submit['id'] = id\n",
    "print(df_submit)\n",
    "submit(source_file=file,data=[df_submit],key=key,no=8)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_solution_class8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
