{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK9q7DEQlmJ1"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxyItFumlmJ4"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "\n",
        "- Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/index.html)\n",
        "- For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
        "\n",
        "**Module 9 Assignment: Detect Multiple Faces**\n",
        "\n",
        "**Student Name: Your Name**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coBqKSu7lmJ4"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "I provide you with five images of people in various poses, such as the following:\n",
        "\n",
        "![Multiple Faces](https://data.heatonresearch.com/images/wustl/data/AdobeStock_319245189-low.jpg)\n",
        "\n",
        "As you have seen from module 9, you can detect faces in this image, as you can see here:\n",
        "\n",
        "![Multiple Faces](https://s3.amazonaws.com/data.heatonresearch.com/images/wustl/class/bound-1.jpg)\n",
        "\n",
        "Your task for this assignment is to extract the coordinates (x,y) and dimensions (height, width). Extract the dimensions/coordinates for a rectangle around the individual face rectangles. This rectangle will overlap the edges of some of the separate face rectangles. The single rectangle would look similar, though you do not need to draw it. Rather, you will return a data frame of the coordinates and dimensions.\n",
        "\n",
        "![Multiple Faces](https://s3.amazonaws.com/data.heatonresearch.com/images/wustl/class/bound-2.jpg)\n",
        "\n",
        "Generate your dataframe from the following images.\n",
        "\n",
        "- https://data.heatonresearch.com/images/wustl/data/AdobeStock_158302589-low.jpg\n",
        "- https://data.heatonresearch.com/images/wustl/data/AdobeStock_268797955-low.jpg\n",
        "- https://data.heatonresearch.com/images/wustl/data/AdobeStock_319245189-low.jpg\n",
        "- https://data.heatonresearch.com/images/wustl/data/AdobeStock_622573012-low.jpg\n",
        "- https://data.heatonresearch.com/images/wustl/data/AdobeStock_632061559-low.jpg\n",
        "\n",
        "Your submitted dataframe should look like this. Make sure to round your numbers and convert to integer. You will need to calculate the width and height.\n",
        "\n",
        "| x   | y   | width | height |\n",
        "| --- | --- | ----- | ------ |\n",
        "| 177 | 215 | 614   | 134    |\n",
        "| 316 | 74  | 472   | 231    |\n",
        "| 231 | 59  | 497   | 264    |\n",
        "| 436 | 160 | 167   | 245    |\n",
        "| 140 | 192 | 760   | 252    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z606GghplmJ5"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to `/content/drive`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sWJdoS7ClmJ5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: not using Google CoLab\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
        "import torch\n",
        "\n",
        "device = (\n",
        "    \"mps\"\n",
        "    if getattr(torch, \"has_mps\", False)\n",
        "    else \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwon6e4vlmJ6"
      },
      "source": [
        "# Assignment Submit Function\n",
        "\n",
        "You will submit the 10 programming assignments electronically. The following submit function can be used to do this. My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n",
        "\n",
        "**It is unlikely that should need to modify this function.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1uVC8RUTlmJ6"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - List of pandas dataframes or images.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    payload = []\n",
        "    for item in data:\n",
        "        if type(item) is PIL.Image.Image:\n",
        "            buffered = BytesIO()\n",
        "            item.save(buffered, format=\"PNG\")\n",
        "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
        "        elif type(item) is pd.core.frame.DataFrame:\n",
        "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
        "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code==200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldLC0Tt2w33w"
      },
      "source": [
        "# Install Facenet-Pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hn0jgYFDw6Tw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: facenet-pytorch in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (2.5.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from facenet-pytorch) (1.25.2)\n",
            "Requirement already satisfied: requests in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from facenet-pytorch) (2.31.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from facenet-pytorch) (0.15.2)\n",
            "Requirement already satisfied: pillow in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from facenet-pytorch) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from requests->facenet-pytorch) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from requests->facenet-pytorch) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from requests->facenet-pytorch) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from requests->facenet-pytorch) (2023.7.22)\n",
            "Requirement already satisfied: torch==2.0.1 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from torchvision->facenet-pytorch) (2.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from torch==2.0.1->torchvision->facenet-pytorch) (4.7.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from torch==2.0.1->torchvision->facenet-pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision->facenet-pytorch) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bloss\\.conda\\envs\\torch\\lib\\site-packages (from sympy->torch==2.0.1->torchvision->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install facenet-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nNXM_k8olmJ7"
      },
      "source": [
        "# Assignment #9 Sample Code\n",
        "\n",
        "The following code provides a starting point for this assignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k85pbdfSqmad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            x           y       width      height\n",
            "0  176.703796  214.599670  614.213867  133.588776\n",
            "1  315.859985   73.516212  472.471558  231.192589\n",
            "2  231.127029   59.369225  496.964523  264.050148\n",
            "3  436.048737  160.210815  167.094208  244.645325\n",
            "4  140.156952  191.794403  759.977692  252.469055\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import torch\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# Load image\n",
        "urls = ['https://data.heatonresearch.com/images/wustl/data/AdobeStock_158302589-low.jpg',\n",
        "       'https://data.heatonresearch.com/images/wustl/data/AdobeStock_268797955-low.jpg',\n",
        "       'https://data.heatonresearch.com/images/wustl/data/AdobeStock_319245189-low.jpg',\n",
        "       'https://data.heatonresearch.com/images/wustl/data/AdobeStock_622573012-low.jpg',\n",
        "       'https://data.heatonresearch.com/images/wustl/data/AdobeStock_632061559-low.jpg']\n",
        "df = pd.DataFrame(columns = ['x', 'y', 'width', 'height'])\n",
        "for url, i in zip(urls, range(5)):\n",
        "    response = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img.load()\n",
        "\n",
        "    # Detect faces\n",
        "    mtcnn = MTCNN(keep_all=True, device=device)\n",
        "    boxes, _ = mtcnn.detect(img)\n",
        "    temp = np.array(boxes)\n",
        "    min_values_first_two_columns = np.min(temp[:, :2], axis=0)\n",
        "    max_values_last_two_columns = np.max(temp[:, -2:], axis=0)\n",
        "    width_height = max_values_last_two_columns - min_values_first_two_columns\n",
        "    new_df = pd.DataFrame({'x': min_values_first_two_columns[0],\n",
        "                       'y': min_values_first_two_columns[1],\n",
        "                       'width': width_height[0],\n",
        "                       'height': width_height[1]}, index=[i])\n",
        "    df = pd.concat([df, new_df], ignore_index=True)\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_-HMgsaqlmJ7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success: Submitted Assignment 9 for n.zixuan:\n",
            "You have submitted this assignment 3 times. (this is fine)\n",
            "No errors, warnings, or notes on your data. Rock on! You will probably do well, but no guarantee. :-)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import torch\n",
        "from PIL import Image, ImageDraw\n",
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"r2nrqz2pX53SGKnwA07UW52mBbNzuLpf8e2ZYIV9\"  # This is an example key and will not work.\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "file='C:\\\\Users\\\\bloss\\\\OneDrive\\\\桌面\\\\T81-558\\\\assignment_Zixuan_class9.ipynb'  # Google CoLab\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class9.ipynb'  # Windows\n",
        "# file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class9.ipynb'  # Mac/Linux\n",
        "\n",
        "df_submit = df.round()\n",
        "\n",
        "# Submit\n",
        "submit(source_file=file,data=[df_submit],key=key,no=9)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
